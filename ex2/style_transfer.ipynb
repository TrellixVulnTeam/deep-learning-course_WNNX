{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Utils needed for the implementation of the paper \"A Neural Algorithm of Artistic Style\"\n",
    "by Gatys et al. in TensorFlow.\n",
    "\n",
    "Author: Chip Huyen (huyenn@stanford.edu)\n",
    "Prepared for the class CS 20SI: \"TensorFlow for Deep Learning Research\"\n",
    "For more details, please read the assignment handout:\n",
    "http://web.stanford.edu/class/cs20si/assignments/a2.pdf\n",
    "\"\"\"\n",
    "import tarfile\n",
    "import os\n",
    "import time\n",
    "import shutil\n",
    "import scipy.io\n",
    "import scipy.misc\n",
    "\n",
    "from PIL import Image, ImageOps\n",
    "from six.moves import urllib\n",
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# AlexNet parameters file\n",
    "ALEXNET_DOWNLOAD_LINK = 'http://www.vlfeat.org/matconvnet/models/imagenet-matconvnet-alex.mat'\n",
    "ALEXNET_MODEL = 'imagenet-matconvnet-alex.mat'\n",
    "ALEXNET_EXPECTED_BYTES = 227414421\n",
    "\n",
    "# GoogLeNet parameters file\n",
    "GOOGLENET_DOWNLOAD_LINK = 'http://download.tensorflow.org/models/inception_v3_2016_08_28.tar.gz'\n",
    "GOOGLENET_MODEL = 'inception_v3.ckpt'\n",
    "GOOGLENET_EXPECTED_BYTES = 100885009\n",
    "\n",
    "# VGG-16 parameters file\n",
    "VGG16_DOWNLOAD_LINK = 'http://www.vlfeat.org/matconvnet/models/imagenet-vgg-verydeep-16.mat'\n",
    "VGG16_MODEL = 'imagenet-vgg-verydeep-16.mat'\n",
    "VGG16_EXPECTED_BYTES = 515063228\n",
    "\n",
    "# VGG-19 parameters file\n",
    "VGG19_DOWNLOAD_LINK = 'http://www.vlfeat.org/matconvnet/models/imagenet-vgg-verydeep-19.mat'\n",
    "VGG19_MODEL = 'imagenet-vgg-verydeep-19.mat'\n",
    "VGG19_EXPECTED_BYTES = 534904783\n",
    "\n",
    "def download(download_link, file_name, expected_bytes):\n",
    "    \"\"\" Download the pretrained model if it's not already downloaded \"\"\"\n",
    "    if os.path.exists(file_name):\n",
    "        print(MODEL_TYPE + \" pre-trained model ready\")\n",
    "        return\n",
    "    print(\"Downloading the \" + MODEL_TYPE + \" pre-trained model. This might take a while ...\")\n",
    "    suffix = download_link.rsplit('/', 1)[1]\n",
    "    urllib.request.urlretrieve(download_link, suffix)\n",
    "    file_stat = os.stat(suffix)\n",
    "    if file_stat.st_size == expected_bytes:\n",
    "        print('Successfully downloaded ' + MODEL_TYPE + ' pre-trained model', suffix)\n",
    "    else:\n",
    "        raise Exception('File ' + suffix +\n",
    "                        ' might be corrupted. You should try downloading it with a browser.')\n",
    "    if MODEL_TYPE == GOOGLENET:\n",
    "        tar = tarfile.open(suffix)\n",
    "        tar.extractall()\n",
    "        tar.close()\n",
    "        os.remove(suffix)\n",
    "\n",
    "def get_resized_image(img_path, height, width, save=True):\n",
    "    image = Image.open(img_path)\n",
    "    # it's because PIL is column major so you have to change place of width and height\n",
    "    # this is stupid, i know\n",
    "    image = ImageOps.fit(image, (width, height), Image.ANTIALIAS)\n",
    "    if save:\n",
    "        image_dirs = img_path.split('/')\n",
    "        image_dirs[-1] = 'resized_' + image_dirs[-1]\n",
    "        out_path = '/'.join(image_dirs)\n",
    "        if not os.path.exists(out_path):\n",
    "            image.save(out_path)\n",
    "    image = np.asarray(image, np.float32)\n",
    "    return np.expand_dims(image, 0)\n",
    "\n",
    "def generate_noise_image(content_image, height, width, noise_ratio=0.6):\n",
    "    if MODEL_TYPE == GOOGLENET:\n",
    "        noise_image = np.random.uniform(-1, 1, (1, height, width, 3)).astype(np.float32)\n",
    "    else:\n",
    "        noise_image = np.random.uniform(-20, 20, (1, height, width, 3)).astype(np.float32)\n",
    "    return noise_image * noise_ratio + content_image * (1 - noise_ratio)\n",
    "\n",
    "def save_image(path, image):\n",
    "    # Output should add back the mean pixels we subtracted at the beginning\n",
    "    image = image[0] # the image\n",
    "    image = np.clip(image, 0, 255).astype('uint8')\n",
    "    scipy.misc.imsave(path, image)\n",
    "    \n",
    "def make_dir(path):\n",
    "    \"\"\" Create a directory if there isn't one already. \"\"\"\n",
    "    try:\n",
    "        os.mkdir(path)\n",
    "    except OSError:\n",
    "        pass\n",
    "    \n",
    "def clean_folders():\n",
    "    if os.path.exists('checkpoints'):\n",
    "        shutil.rmtree('checkpoints')\n",
    "    if os.path.exists('outputs'):\n",
    "        shutil.rmtree('outputs')\n",
    "\n",
    "def load_model(input_image):\n",
    "    global STYLE_LAYERS, CONTENT_LAYER\n",
    "    if MODEL_TYPE == VGG19:\n",
    "        print('Loading VGG-19')\n",
    "        STYLE_LAYERS = ['conv1_1', 'conv2_1', 'conv3_1', 'conv4_1', 'conv5_1']\n",
    "        CONTENT_LAYER = 'conv4_2'\n",
    "        download(VGG19_DOWNLOAD_LINK, VGG19_MODEL, VGG19_EXPECTED_BYTES)\n",
    "        return load_vgg19(VGG19_MODEL, input_image)\n",
    "    if MODEL_TYPE == VGG16:\n",
    "        print('Loading VGG-16')\n",
    "        STYLE_LAYERS = ['conv1_1', 'conv2_1', 'conv3_1', 'conv4_1', 'conv5_1']\n",
    "        CONTENT_LAYER = 'conv4_2'\n",
    "        download(VGG16_DOWNLOAD_LINK, VGG16_MODEL, VGG16_EXPECTED_BYTES)\n",
    "        return load_vgg16(VGG16_MODEL, input_image)\n",
    "    if MODEL_TYPE == ALEXNET:    \n",
    "        print('Loading AlexNet')\n",
    "        STYLE_LAYERS = ['conv1_1', 'conv2_1', 'conv3_1', 'conv5_1']\n",
    "        CONTENT_LAYER = 'conv4_1'\n",
    "        download(ALEXNET_DOWNLOAD_LINK, ALEXNET_MODEL, ALEXNET_EXPECTED_BYTES)\n",
    "        return load_alexnet(ALEXNET_MODEL, input_image)\n",
    "    if MODEL_TYPE == GOOGLENET:    \n",
    "        print('Loading GoogLeNet')\n",
    "        STYLE_LAYERS = ['Conv2d_1a_3x3', 'Conv2d_2a_3x3', 'Conv2d_3b_1x1', 'Conv2d_4a_3x3']\n",
    "        CONTENT_LAYER = 'Conv2d_2b_3x3'\n",
    "        download(GOOGLENET_DOWNLOAD_LINK, GOOGLENET_MODEL, GOOGLENET_EXPECTED_BYTES)\n",
    "        return load_googlenet(GOOGLENET_MODEL, input_image)\n",
    "    raise ValueError('No such model type')\n",
    "    \n",
    "def initialize_hyperparameters():\n",
    "    if MODEL_TYPE == ALEXNET:\n",
    "        W = [1.0, 1.0, 1.0, 1.0, 1.0]\n",
    "        LR = 2\n",
    "        CONTENT_WEIGHT = 10.0\n",
    "        STYLE_WEIGHT = 1000.0\n",
    "        ITERS = 300\n",
    "    elif MODEL_TYPE == VGG16 or MODEL_TYPE == VGG19:\n",
    "        W = [0.5, 1.0, 1.5, 3.0, 4.0]\n",
    "        LR = 2\n",
    "        CONTENT_WEIGHT = 10\n",
    "        STYLE_WEIGHT = 0.001\n",
    "        ITERS = 300\n",
    "    elif MODEL_TYPE == GOOGLENET:\n",
    "        W = [0.5, 1.0, 1.5, 3.0, 4.0]\n",
    "        LR = 0.001\n",
    "        CONTENT_WEIGHT = 10\n",
    "        STYLE_WEIGHT = 0.001\n",
    "        ITERS = 300\n",
    "    else:\n",
    "        raise ValueError('No such model type')\n",
    "    return W, LR, CONTENT_WEIGHT, STYLE_WEIGHT, ITERS\n",
    "\n",
    "def _weights(layers, layer, expected_layer_name):\n",
    "    if MODEL_TYPE == VGG16 or MODEL_TYPE == VGG19:\n",
    "        \"\"\" Return the weights and biases already trained by VGG\n",
    "        \"\"\"\n",
    "        W = layers[0][layer][0][0][2][0][0]\n",
    "        b = layers[0][layer][0][0][2][0][1]\n",
    "        layer_name = layers[0][layer][0][0][0][0]\n",
    "    elif MODEL_TYPE == ALEXNET:\n",
    "        \"\"\" Return the weights and biases already trained by AlexNet\n",
    "        \"\"\"\n",
    "        W = layers[0][layer][1]\n",
    "        b = layers[0][layer + 1][1]\n",
    "        layer_name = layers[0][layer][0]\n",
    "    else:\n",
    "        raise ValueError('No such model type')\n",
    "    assert layer_name == expected_layer_name\n",
    "    return W, b.reshape(b.size)\n",
    "\n",
    "def _conv2d_relu(layers, prev_layer, layer, layer_name, group=1):\n",
    "    \"\"\" Return the Conv2D layer with RELU using the weights, biases from the VGG\n",
    "    model at 'layer'.\n",
    "    Inputs:\n",
    "        layers: holding all the layers of net\n",
    "        prev_layer: the output tensor from the previous layer\n",
    "        layer: the index to current layer in layers\n",
    "        layer_name: the string that is the name of the current layer.\n",
    "                    It's used to specify variable_scope.\n",
    "        group: the index of the group\n",
    "\n",
    "    Output:\n",
    "        relu applied on the convolution.\n",
    "\n",
    "    Note that you first need to obtain W and b from layers using the function\n",
    "    _weights() defined above.\n",
    "    W and b returned from _weights() are numpy arrays, so you have\n",
    "    to convert them to TF tensors using tf.constant.\n",
    "    Note that you'll have to do apply relu on the convolution.\n",
    "    Hint for choosing strides size: \n",
    "        for small images, you probably don't want to skip any pixel\n",
    "    \"\"\"\n",
    "    \n",
    "    with tf.variable_scope(layer_name) as scope:\n",
    "        W, b = _weights(layers, layer, layer_name)\n",
    "        W = tf.constant(W, name='weights')\n",
    "        b = tf.constant(b, name='bias')\n",
    "        if group == 1:\n",
    "            conv2d = tf.nn.conv2d(prev_layer, filter=W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "            return tf.nn.relu(conv2d + b)\n",
    "        if group == 2:\n",
    "            groups_in = tf.split(prev_layer, 2, 3)\n",
    "            groups_ker = tf.split(W, 2, 3)\n",
    "            groups_out = [tf.nn.conv2d(i, k, [1, 1, 1, 1], padding='SAME')\n",
    "                             for i, k in zip(groups_in, groups_ker)]\n",
    "            conv2d = tf.concat(groups_out, 3)\n",
    "            conv2d = tf.reshape(tf.nn.bias_add(conv2d, b), [-1] + \n",
    "                                conv2d.get_shape().as_list()[1:])\n",
    "            return tf.nn.relu(conv2d)\n",
    "\n",
    "def _avgpool(prev_layer):\n",
    "    \"\"\" Return the average pooling layer. The paper suggests that average pooling\n",
    "    actually works better than max pooling.\n",
    "    Input:\n",
    "        prev_layer: the output tensor from the previous layer\n",
    "\n",
    "    Output:\n",
    "        the output of the tf.nn.avg_pool() function.\n",
    "    Hint for choosing strides and kszie: choose what you feel appropriate\n",
    "    \"\"\"\n",
    "    return tf.nn.avg_pool(prev_layer, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], \n",
    "                          padding='SAME', name='avg_pool_')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AlexNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_alexnet(path, input_image):\n",
    "    \"\"\" Load AlexNet into a TensorFlow model.\n",
    "    Use a dictionary to hold the model instead of using a Python class\n",
    "    \"\"\"\n",
    "    alexnet = scipy.io.loadmat(path)\n",
    "    alexnet_params = alexnet['params']\n",
    "    \n",
    "    graph = {} \n",
    "    graph['conv1_1']  = _conv2d_relu(alexnet_params, input_image, 0, 'conv1f')\n",
    "    graph['avgpool1'] = _avgpool(graph['conv1_1'])\n",
    "    graph['conv2_1']  = _conv2d_relu(alexnet_params, graph['avgpool1'], 2, 'conv2f', 2)\n",
    "    graph['avgpool2'] = _avgpool(graph['conv2_1'])\n",
    "    graph['conv3_1']  = _conv2d_relu(alexnet_params, graph['avgpool2'], 4, 'conv3f')\n",
    "    graph['conv4_1']  = _conv2d_relu(alexnet_params, graph['conv3_1'], 6, 'conv4f', 2)\n",
    "    graph['conv5_1']  = _conv2d_relu(alexnet_params, graph['conv4_1'], 8, 'conv5f', 2)\n",
    "    graph['avgpool5'] = _avgpool(graph['conv5_1'])\n",
    "    \n",
    "    return graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GoogLeNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.contrib.slim.nets import inception\n",
    "import tensorflow.contrib.slim as slim\n",
    "\n",
    "def load_googlenet(path, input_image):\n",
    "    with slim.arg_scope(inception.inception_v3_arg_scope()):\n",
    "        logits, end_points = inception.inception_v3(input_image, num_classes=1001, \n",
    "                                                    is_training=False)\n",
    "    return end_points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VGG-16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_vgg16(path, input_image):\n",
    "    \"\"\" Load VGG into a TensorFlow model.\n",
    "    Use a dictionary to hold the model instead of using a Python class\n",
    "    \"\"\"\n",
    "    vgg = scipy.io.loadmat(path)\n",
    "    vgg_layers = vgg['layers']\n",
    "\n",
    "    graph = {} \n",
    "    graph['conv1_1']  = _conv2d_relu(vgg_layers, input_image, 0, 'conv1_1')\n",
    "    graph['conv1_2']  = _conv2d_relu(vgg_layers, graph['conv1_1'], 2, 'conv1_2')\n",
    "    graph['avgpool1'] = _avgpool(graph['conv1_2'])\n",
    "    graph['conv2_1']  = _conv2d_relu(vgg_layers, graph['avgpool1'], 5, 'conv2_1')\n",
    "    graph['conv2_2']  = _conv2d_relu(vgg_layers, graph['conv2_1'], 7, 'conv2_2')\n",
    "    graph['avgpool2'] = _avgpool(graph['conv2_2'])\n",
    "    graph['conv3_1']  = _conv2d_relu(vgg_layers, graph['avgpool2'], 10, 'conv3_1')\n",
    "    graph['conv3_2']  = _conv2d_relu(vgg_layers, graph['conv3_1'], 12, 'conv3_2')\n",
    "    graph['conv3_3']  = _conv2d_relu(vgg_layers, graph['conv3_2'], 14, 'conv3_3')\n",
    "    graph['avgpool3'] = _avgpool(graph['conv3_3'])\n",
    "    graph['conv4_1']  = _conv2d_relu(vgg_layers, graph['avgpool3'], 17, 'conv4_1')\n",
    "    graph['conv4_2']  = _conv2d_relu(vgg_layers, graph['conv4_1'], 19, 'conv4_2')\n",
    "    graph['conv4_3']  = _conv2d_relu(vgg_layers, graph['conv4_2'], 21, 'conv4_3')\n",
    "    graph['avgpool4'] = _avgpool(graph['conv4_3'])\n",
    "    graph['conv5_1']  = _conv2d_relu(vgg_layers, graph['avgpool4'], 24, 'conv5_1')\n",
    "    graph['conv5_2']  = _conv2d_relu(vgg_layers, graph['conv5_1'], 26, 'conv5_2')\n",
    "    graph['conv5_3']  = _conv2d_relu(vgg_layers, graph['conv5_2'], 28, 'conv5_3')\n",
    "    graph['avgpool5'] = _avgpool(graph['conv5_3'])\n",
    "    \n",
    "    return graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VGG-19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_vgg19(path, input_image):\n",
    "    \"\"\" Load VGG into a TensorFlow model.\n",
    "    Use a dictionary to hold the model instead of using a Python class\n",
    "    \"\"\"\n",
    "    vgg = scipy.io.loadmat(path)\n",
    "    vgg_layers = vgg['layers']\n",
    "\n",
    "    graph = {} \n",
    "    graph['conv1_1']  = _conv2d_relu(vgg_layers, input_image, 0, 'conv1_1')\n",
    "    graph['conv1_2']  = _conv2d_relu(vgg_layers, graph['conv1_1'], 2, 'conv1_2')\n",
    "    graph['avgpool1'] = _avgpool(graph['conv1_2'])\n",
    "    graph['conv2_1']  = _conv2d_relu(vgg_layers, graph['avgpool1'], 5, 'conv2_1')\n",
    "    graph['conv2_2']  = _conv2d_relu(vgg_layers, graph['conv2_1'], 7, 'conv2_2')\n",
    "    graph['avgpool2'] = _avgpool(graph['conv2_2'])\n",
    "    graph['conv3_1']  = _conv2d_relu(vgg_layers, graph['avgpool2'], 10, 'conv3_1')\n",
    "    graph['conv3_2']  = _conv2d_relu(vgg_layers, graph['conv3_1'], 12, 'conv3_2')\n",
    "    graph['conv3_3']  = _conv2d_relu(vgg_layers, graph['conv3_2'], 14, 'conv3_3')\n",
    "    graph['conv3_4']  = _conv2d_relu(vgg_layers, graph['conv3_3'], 16, 'conv3_4')\n",
    "    graph['avgpool3'] = _avgpool(graph['conv3_4'])\n",
    "    graph['conv4_1']  = _conv2d_relu(vgg_layers, graph['avgpool3'], 19, 'conv4_1')\n",
    "    graph['conv4_2']  = _conv2d_relu(vgg_layers, graph['conv4_1'], 21, 'conv4_2')\n",
    "    graph['conv4_3']  = _conv2d_relu(vgg_layers, graph['conv4_2'], 23, 'conv4_3')\n",
    "    graph['conv4_4']  = _conv2d_relu(vgg_layers, graph['conv4_3'], 25, 'conv4_4')\n",
    "    graph['avgpool4'] = _avgpool(graph['conv4_4'])\n",
    "    graph['conv5_1']  = _conv2d_relu(vgg_layers, graph['avgpool4'], 28, 'conv5_1')\n",
    "    graph['conv5_2']  = _conv2d_relu(vgg_layers, graph['conv5_1'], 30, 'conv5_2')\n",
    "    graph['conv5_3']  = _conv2d_relu(vgg_layers, graph['conv5_2'], 32, 'conv5_3')\n",
    "    graph['conv5_4']  = _conv2d_relu(vgg_layers, graph['conv5_3'], 34, 'conv5_4')\n",
    "    graph['avgpool5'] = _avgpool(graph['conv5_4'])\n",
    "    \n",
    "    return graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Style Transfer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading GoogLeNet\n",
      "googlenet pre-trained model ready\n",
      "INFO:tensorflow:Restoring parameters from inception_v3.ckpt\n",
      "INFO:tensorflow:Restoring parameters from inception_v3.ckpt\n",
      "INFO:tensorflow:Restoring parameters from inception_v3.ckpt\n",
      "Step 1\n",
      "   Sum: 95963.0\n",
      "   Loss:   2.2\n",
      "   Time: 0.981490850449\n",
      "Step 2\n",
      "   Sum: 95963.0\n",
      "   Loss:   2.1\n",
      "   Time: 0.564149856567\n",
      "Step 3\n",
      "   Sum: 95962.9\n",
      "   Loss:   2.1\n",
      "   Time: 0.52145409584\n",
      "Step 4\n",
      "   Sum: 95962.9\n",
      "   Loss:   2.1\n",
      "   Time: 0.558972120285\n",
      "Step 5\n",
      "   Sum: 95962.9\n",
      "   Loss:   2.1\n",
      "   Time: 0.559689044952\n",
      "Step 10\n",
      "   Sum: 95962.9\n",
      "   Loss:   2.0\n",
      "   Time: 2.22782897949\n",
      "Step 20\n",
      "   Sum: 95962.9\n",
      "   Loss:   1.8\n",
      "   Time: 4.49563789368\n",
      "Step 40\n",
      "   Sum: 95962.9\n",
      "   Loss:   1.6\n",
      "   Time: 19.2844090462\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-77867e44432f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[0minitial_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_noise_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontent_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIMAGE_HEIGHT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIMAGE_WIDTH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNOISE_RATIO\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-6-77867e44432f>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, generated_image, initial_image)\u001b[0m\n\u001b[1;32m    175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m20\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 177\u001b[0;31m                     \u001b[0msaver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'checkpoints/style_transfer'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[0mreset_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda2/lib/python2.7/site-packages/tensorflow/python/training/saver.pyc\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, sess, save_path, global_step, latest_filename, meta_graph_suffix, write_meta_graph, write_state)\u001b[0m\n\u001b[1;32m   1494\u001b[0m           checkpoint_file, meta_graph_suffix=meta_graph_suffix)\n\u001b[1;32m   1495\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1496\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexport_meta_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmeta_graph_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1497\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1498\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_empty\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda2/lib/python2.7/site-packages/tensorflow/python/training/saver.pyc\u001b[0m in \u001b[0;36mexport_meta_graph\u001b[0;34m(self, filename, collection_list, as_text, export_scope, clear_devices, clear_extraneous_savers)\u001b[0m\n\u001b[1;32m   1532\u001b[0m         \u001b[0mexport_scope\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexport_scope\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1533\u001b[0m         \u001b[0mclear_devices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclear_devices\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1534\u001b[0;31m         clear_extraneous_savers=clear_extraneous_savers)\n\u001b[0m\u001b[1;32m   1535\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1536\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrestore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda2/lib/python2.7/site-packages/tensorflow/python/training/saver.pyc\u001b[0m in \u001b[0;36mexport_meta_graph\u001b[0;34m(filename, meta_info_def, graph_def, saver_def, collection_list, as_text, graph, export_scope, clear_devices, clear_extraneous_savers, **kwargs)\u001b[0m\n\u001b[1;32m   1765\u001b[0m       \u001b[0mclear_devices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclear_devices\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1766\u001b[0m       \u001b[0mclear_extraneous_savers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclear_extraneous_savers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1767\u001b[0;31m       **kwargs)\n\u001b[0m\u001b[1;32m   1768\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mmeta_graph_def\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1769\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/meta_graph.pyc\u001b[0m in \u001b[0;36mexport_scoped_meta_graph\u001b[0;34m(filename, graph_def, graph, export_scope, as_text, unbound_inputs_col_name, clear_devices, saver_def, clear_extraneous_savers, **kwargs)\u001b[0m\n\u001b[1;32m    834\u001b[0m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdirname\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 836\u001b[0;31m         as_text=as_text)\n\u001b[0m\u001b[1;32m    837\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    838\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mscoped_meta_graph_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar_list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/graph_io.pyc\u001b[0m in \u001b[0;36mwrite_graph\u001b[0;34m(graph_or_graph_def, logdir, name, as_text)\u001b[0m\n\u001b[1;32m     69\u001b[0m                                         text_format.MessageToString(graph_def))\n\u001b[1;32m     70\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m     \u001b[0mfile_io\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0matomic_write_string_to_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSerializeToString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda2/lib/python2.7/site-packages/google/protobuf/internal/python_message.pyc\u001b[0m in \u001b[0;36mSerializeToString\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m   1040\u001b[0m           'Message %s is missing required fields: %s' % (\n\u001b[1;32m   1041\u001b[0m           self.DESCRIPTOR.full_name, ','.join(self.FindInitializationErrors())))\n\u001b[0;32m-> 1042\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSerializePartialToString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1043\u001b[0m   \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSerializeToString\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSerializeToString\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1044\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda2/lib/python2.7/site-packages/google/protobuf/internal/python_message.pyc\u001b[0m in \u001b[0;36mSerializePartialToString\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mSerializePartialToString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1050\u001b[0m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1051\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_InternalSerialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m   \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSerializePartialToString\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSerializePartialToString\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda2/lib/python2.7/site-packages/google/protobuf/internal/python_message.pyc\u001b[0m in \u001b[0;36mInternalSerialize\u001b[0;34m(self, write_bytes, deterministic)\u001b[0m\n\u001b[1;32m   1069\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1070\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mfield_descriptor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfield_value\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mListFields\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1071\u001b[0;31m         \u001b[0mfield_descriptor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_encoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrite_bytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfield_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeterministic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1072\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mtag_bytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue_bytes\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_unknown_fields\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1073\u001b[0m         \u001b[0mwrite_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtag_bytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda2/lib/python2.7/site-packages/google/protobuf/internal/encoder.pyc\u001b[0m in \u001b[0;36mEncodeField\u001b[0;34m(write, value, deterministic)\u001b[0m\n\u001b[1;32m    763\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mEncodeField\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeterministic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m       \u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 765\u001b[0;31m       \u001b[0mlocal_EncodeVarint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mByteSize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeterministic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    766\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_InternalSerialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeterministic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mEncodeField\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda2/lib/python2.7/site-packages/google/protobuf/internal/python_message.pyc\u001b[0m in \u001b[0;36mByteSize\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1018\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1019\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mfield_descriptor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfield_value\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mListFields\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1020\u001b[0;31m         \u001b[0msize\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mfield_descriptor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfield_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1021\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mtag_bytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue_bytes\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_unknown_fields\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1022\u001b[0m         \u001b[0msize\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtag_bytes\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue_bytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda2/lib/python2.7/site-packages/google/protobuf/internal/encoder.pyc\u001b[0m in \u001b[0;36mRepeatedFieldSize\u001b[0;34m(value)\u001b[0m\n\u001b[1;32m    300\u001b[0m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtag_size\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0melement\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 302\u001b[0;31m         \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0melement\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mByteSize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    303\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlocal_VarintSize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda2/lib/python2.7/site-packages/google/protobuf/internal/python_message.pyc\u001b[0m in \u001b[0;36mByteSize\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1018\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1019\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mfield_descriptor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfield_value\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mListFields\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1020\u001b[0;31m         \u001b[0msize\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mfield_descriptor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfield_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1021\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mtag_bytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue_bytes\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_unknown_fields\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1022\u001b[0m         \u001b[0msize\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtag_bytes\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue_bytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda2/lib/python2.7/site-packages/google/protobuf/internal/encoder.pyc\u001b[0m in \u001b[0;36mFieldSize\u001b[0;34m(map_value)\u001b[0m\n\u001b[1;32m    361\u001b[0m       \u001b[0mtotal\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mmessage_sizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentry_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mis_message_map\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 363\u001b[0;31m         \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mByteSize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtotal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda2/lib/python2.7/site-packages/google/protobuf/internal/python_message.pyc\u001b[0m in \u001b[0;36mByteSize\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1018\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1019\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mfield_descriptor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfield_value\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mListFields\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1020\u001b[0;31m         \u001b[0msize\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mfield_descriptor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfield_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1021\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mtag_bytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue_bytes\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_unknown_fields\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1022\u001b[0m         \u001b[0msize\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtag_bytes\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue_bytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda2/lib/python2.7/site-packages/google/protobuf/internal/encoder.pyc\u001b[0m in \u001b[0;36mFieldSize\u001b[0;34m(value)\u001b[0m\n\u001b[1;32m    306\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mFieldSize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 308\u001b[0;31m       \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mByteSize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    309\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mtag_size\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlocal_VarintSize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mFieldSize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda2/lib/python2.7/site-packages/google/protobuf/internal/python_message.pyc\u001b[0m in \u001b[0;36mByteSize\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1018\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1019\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mfield_descriptor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfield_value\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mListFields\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1020\u001b[0;31m         \u001b[0msize\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mfield_descriptor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfield_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1021\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mtag_bytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue_bytes\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_unknown_fields\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1022\u001b[0m         \u001b[0msize\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtag_bytes\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue_bytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda2/lib/python2.7/site-packages/google/protobuf/internal/encoder.pyc\u001b[0m in \u001b[0;36mRepeatedFieldSize\u001b[0;34m(value)\u001b[0m\n\u001b[1;32m    300\u001b[0m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtag_size\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0melement\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 302\u001b[0;31m         \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0melement\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mByteSize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    303\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlocal_VarintSize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda2/lib/python2.7/site-packages/google/protobuf/internal/python_message.pyc\u001b[0m in \u001b[0;36mByteSize\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1018\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1019\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mfield_descriptor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfield_value\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mListFields\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1020\u001b[0;31m         \u001b[0msize\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mfield_descriptor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfield_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1021\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mtag_bytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue_bytes\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_unknown_fields\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1022\u001b[0m         \u001b[0msize\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtag_bytes\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue_bytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda2/lib/python2.7/site-packages/google/protobuf/internal/encoder.pyc\u001b[0m in \u001b[0;36mRepeatedFieldSize\u001b[0;34m(value)\u001b[0m\n\u001b[1;32m    300\u001b[0m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtag_size\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0melement\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 302\u001b[0;31m         \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0melement\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mByteSize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    303\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlocal_VarintSize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda2/lib/python2.7/site-packages/google/protobuf/internal/python_message.pyc\u001b[0m in \u001b[0;36mByteSize\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1006\u001b[0m   \u001b[0;34m\"\"\"Helper for _AddMessageMethods().\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1007\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1008\u001b[0;31m   \u001b[0;32mdef\u001b[0m \u001b[0mByteSize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1009\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cached_byte_size_dirty\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1010\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cached_byte_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\"\"\" An implementation of the paper \"A Neural Algorithm of Artistic Style\"\n",
    "by Gatys et al. in TensorFlow.\n",
    "\n",
    "Author: Chip Huyen (huyenn@stanford.edu)\n",
    "Prepared for the class CS 20SI: \"TensorFlow for Deep Learning Research\"\n",
    "For more details, please read the assignment handout:\n",
    "http://web.stanford.edu/class/cs20si/assignments/a2.pdf\n",
    "\"\"\"\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL']='2'\n",
    "\n",
    "# parameters to manage experiments\n",
    "\n",
    "STYLE = 'dali'\n",
    "CONTENT = 'max'\n",
    "\n",
    "STYLE_IMAGE = 'styles/' + STYLE + '.jpg'\n",
    "CONTENT_IMAGE = 'content/' + CONTENT + '.jpg'\n",
    "IMAGE_HEIGHT = 299\n",
    "IMAGE_WIDTH = 299\n",
    "NOISE_RATIO = 0.6 # percentage of weight of the noise for intermixing with the content image\n",
    "\n",
    "MEAN_PIXELS = np.array([123.68, 116.779, 103.939]).reshape((1,1,1,3))\n",
    "\"\"\" MEAN_PIXELS is defined according to description on their github:\n",
    "https://gist.github.com/ksimonyan/211839e770f7b538e2d8\n",
    "'In the paper, the model is denoted as the configuration D trained with scale jittering. \n",
    "The input images should be zero-centered by mean pixel (rather than mean image) subtraction. \n",
    "Namely, the following BGR values should be subtracted: [103.939, 116.779, 123.68].'\n",
    "\"\"\"\n",
    "\n",
    "ALEXNET = 'alexnet'\n",
    "VGG16 = 'vgg16'\n",
    "VGG19 = 'vgg19'\n",
    "GOOGLENET = 'googlenet' # NOT WORKING!\n",
    "\n",
    "# model to run (ALEXNET | GOOGLENET | VGG16 | VGG19)\n",
    "MODEL_TYPE = GOOGLENET\n",
    "\n",
    "W, LR, CONTENT_WEIGHT, STYLE_WEIGHT, ITERS = initialize_hyperparameters()\n",
    "\n",
    "def reset_graph(seed=42):\n",
    "    tf.reset_default_graph()\n",
    "    tf.set_random_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "def _create_content_loss(p, f):\n",
    "    \"\"\" Calculate the loss between the feature representation of the\n",
    "    content image and the generated image.\n",
    "    \n",
    "    Inputs: \n",
    "        p, f are just P, F in the paper \n",
    "        (read the assignment handout if you're confused)\n",
    "        Note: we won't use the coefficient 0.5 as defined in the paper\n",
    "        but the coefficient as defined in the assignment handout.\n",
    "    Output:\n",
    "        the content loss\n",
    "\n",
    "    \"\"\"\n",
    "    return tf.reduce_sum((f - p) ** 2) / (4.0 * p.size)\n",
    "\n",
    "def _gram_matrix(F, N, M):\n",
    "    \"\"\" Create and return the gram matrix for tensor F\n",
    "        Hint: you'll first have to reshape F\n",
    "    \"\"\"\n",
    "    F = tf.reshape(F, (M, N))\n",
    "    return tf.matmul(tf.transpose(F), F)\n",
    "\n",
    "def _single_style_loss(a, g):\n",
    "    \"\"\" Calculate the style loss at a certain layer\n",
    "    Inputs:\n",
    "        a is the feature representation of the real image\n",
    "        g is the feature representation of the generated image\n",
    "    Output:\n",
    "        the style loss at a certain layer (which is E_l in the paper)\n",
    "\n",
    "    Hint: 1. you'll have to use the function _gram_matrix()\n",
    "        2. we'll use the same coefficient for style loss as in the paper\n",
    "        3. a and g are feature representation, not gram matrices\n",
    "    \"\"\"\n",
    "    N = a.shape[3] # number of filters\n",
    "    M = a.shape[1] * a.shape[2] # height times width of the feature map\n",
    "    A = _gram_matrix(a, N, M)\n",
    "    G = _gram_matrix(g, N, M)\n",
    "    return tf.reduce_sum((G - A) ** 2 / ((2 * N * M) ** 2))\n",
    "\n",
    "def _create_style_loss(A, model):\n",
    "    \"\"\" Return the total style loss\n",
    "    \"\"\"\n",
    "    n_layers = len(STYLE_LAYERS)\n",
    "    E = [_single_style_loss(A[i], model[STYLE_LAYERS[i]]) for i in range(n_layers)]\n",
    "    \n",
    "    return sum([W[i] * E[i] for i in range(n_layers)])\n",
    "\n",
    "def restore_model(sess, saver=None):\n",
    "    if MODEL_TYPE == GOOGLENET:\n",
    "        global_vars = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope='InceptionV3')\n",
    "        saver = tf.train.Saver(global_vars)\n",
    "        saver.restore(sess, GOOGLENET_MODEL)\n",
    "    else:\n",
    "        ckpt = tf.train.get_checkpoint_state(os.path.dirname('checkpoints/checkpoint'))\n",
    "        if ckpt and ckpt.model_checkpoint_path:\n",
    "            saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "\n",
    "def _create_losses(model, input_image, content_image, style_image):\n",
    "    with tf.variable_scope('loss') as scope:\n",
    "        with tf.Session() as sess:\n",
    "            restore_model(sess)\n",
    "            sess.run(input_image.assign(content_image))\n",
    "            p = sess.run(model[CONTENT_LAYER])\n",
    "        content_loss = _create_content_loss(p, model[CONTENT_LAYER])\n",
    "\n",
    "        with tf.Session() as sess:\n",
    "            restore_model(sess)\n",
    "            sess.run(input_image.assign(style_image))\n",
    "            A = sess.run([model[layer_name] for layer_name in STYLE_LAYERS])                              \n",
    "        style_loss = _create_style_loss(A, model)\n",
    "        total_loss = CONTENT_WEIGHT * content_loss + STYLE_WEIGHT * style_loss\n",
    "\n",
    "    return content_loss, style_loss, total_loss\n",
    "\n",
    "def _create_summary(model):\n",
    "    \"\"\" Create summary ops necessary\n",
    "        Hint: don't forget to merge them\n",
    "    \"\"\"\n",
    "    with tf.name_scope('summaries'):\n",
    "        tf.summary.scalar('content_loss', model['content_loss'])\n",
    "        tf.summary.scalar('style_loss', model['style_loss'])\n",
    "        tf.summary.scalar('total_loss', model['total_loss'])\n",
    "        tf.summary.histogram('histogram_content_loss', model['content_loss'])\n",
    "        tf.summary.histogram('histogram_style_loss', model['style_loss'])\n",
    "        tf.summary.histogram('histogram_total_loss', model['total_loss'])\n",
    "        return tf.summary.merge_all()\n",
    "    \n",
    "def train(model, generated_image, initial_image):\n",
    "    \"\"\" Train your model.\n",
    "    Don't forget to create folders for checkpoints and outputs.\n",
    "    \"\"\"\n",
    "    skip_step = 1\n",
    "    with tf.Session() as sess:\n",
    "        saver = tf.train.Saver()\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        writer = tf.summary.FileWriter('graphs', sess.graph)\n",
    "        sess.run(generated_image.assign(initial_image))\n",
    "        restore_model(sess, saver)\n",
    "        initial_step = model['global_step'].eval()\n",
    "        \n",
    "        start_time = time.time()\n",
    "        for index in range(initial_step, ITERS):\n",
    "            if index >= 5 and index < 20:\n",
    "                skip_step = 10\n",
    "            elif index >= 20:\n",
    "                skip_step = 20\n",
    "            \n",
    "            sess.run(model['optimizer'])\n",
    "            if (index + 1) % skip_step == 0:\n",
    "                gen_image, total_loss, summary = sess.run([generated_image, model['total_loss'], \n",
    "                                                             model['summary_op']])\n",
    "                if MODEL_TYPE == GOOGLENET:\n",
    "                    gen_image = gen_image + MEAN_PIXELS / 255\n",
    "                else:\n",
    "                    gen_image = gen_image + MEAN_PIXELS\n",
    "                writer.add_summary(summary, global_step=index)\n",
    "                print('Step {}\\n   Sum: {:5.1f}'.format(index + 1, np.sum(gen_image)))\n",
    "                print('   Loss: {:5.1f}'.format(total_loss))\n",
    "                print('   Time: {}'.format(time.time() - start_time))\n",
    "                start_time = time.time()\n",
    "\n",
    "                filename = 'outputs/%d.png' % (index)\n",
    "                \n",
    "                if (MODEL_TYPE == GOOGLENET):\n",
    "                    # normalize back to 0 and 255\n",
    "                    gen_image *= (255.0 / gen_image.max())\n",
    "                \n",
    "                save_image(filename, gen_image)\n",
    "\n",
    "                if (index + 1) % 20 == 0:\n",
    "                    saver.save(sess, 'checkpoints/style_transfer', index)\n",
    "\n",
    "reset_graph()\n",
    "clean_folders()\n",
    "    \n",
    "with tf.variable_scope('input') as scope:\n",
    "    # use variable instead of placeholder because we're training the intial image to make it\n",
    "    # look like both the content image and the style image\n",
    "    input_image = tf.Variable(np.zeros([1, IMAGE_HEIGHT, IMAGE_WIDTH, 3]), dtype=tf.float32)\n",
    "    \n",
    "make_dir('checkpoints')\n",
    "make_dir('outputs')\n",
    "model = load_model(input_image)\n",
    "model['global_step'] = tf.Variable(0, dtype=tf.int32, trainable=False, name='global_step')\n",
    "\n",
    "content_image = get_resized_image(CONTENT_IMAGE, IMAGE_HEIGHT, IMAGE_WIDTH)\n",
    "content_image = content_image - MEAN_PIXELS\n",
    "style_image = get_resized_image(STYLE_IMAGE, IMAGE_HEIGHT, IMAGE_WIDTH)\n",
    "style_image = style_image - MEAN_PIXELS\n",
    "\n",
    "if (MODEL_TYPE == GOOGLENET):\n",
    "    # normalize between -1 and 1\n",
    "    content_image[0] /= 255\n",
    "    style_image[0] /= 255\n",
    "    \n",
    "model['content_loss'], model['style_loss'], model['total_loss'] = _create_losses(model, \n",
    "                                                input_image, content_image, style_image)\n",
    "if MODEL_TYPE == GOOGLENET:\n",
    "    model['optimizer'] = tf.train.GradientDescentOptimizer(LR).minimize(model['total_loss'], \n",
    "                                                                        global_step=model['global_step'])\n",
    "else:\n",
    "    model['optimizer'] = tf.train.AdamOptimizer(LR).minimize(model['total_loss'], \n",
    "                                                             global_step=model['global_step'])\n",
    "model['summary_op'] = _create_summary(model)\n",
    "\n",
    "initial_image = generate_noise_image(content_image, IMAGE_HEIGHT, IMAGE_WIDTH, NOISE_RATIO)\n",
    "train(model, input_image, initial_image)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
